{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 1. Import Libraries and Setup\n",
    "# ====================================\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# ====================================\n",
    "# 2. Data Loading\n",
    "# ====================================\n",
    "def load_pickle_data(file_path):\n",
    "    \"\"\"\n",
    "    Attempt to load a DataFrame from a pickle file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the pickle file.\n",
    "        \n",
    "    Returns:\n",
    "        data (DataFrame): The loaded pandas DataFrame or None if file is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Data successfully loaded from: {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found. Check the file path and try again.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\1176801963.py:18: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  data = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: NetGEX_AbsGEX_EPS(AAPL).pickle\n",
      "Columns in the loaded data:\n",
      "['Spot_Open', 'Spot_Close', 'Spot_High', 'Spot_Low', 'PCT_EPS_1mo_Open', 'PCT_EPS_1mo_Close', 'PCT_EPS_1mo_High', 'PCT_EPS_1mo_Low', 'open_abs_gex', 'high_abs_gex', 'low_abs_gex', 'close_abs_gex', 'volume_abs_gex', 'open_net_gex', 'high_net_gex', 'low_net_gex', 'close_net_gex', 'volume_net_gex']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# File path provided by the user\n",
    "file_path = \"NetGEX_AbsGEX_EPS(AAPL).pickle\"\n",
    "data = load_pickle_data(file_path)\n",
    "\n",
    "if data is not None:\n",
    "    print(\"Columns in the loaded data:\")\n",
    "    print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data.index)\n",
    "data.sort_values('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after preprocessing and feature engineering:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Feature: Daily Return ---\n",
    "# Calculate daily return using Spot_Close.\n",
    "data['daily_return'] = data['Spot_Close'].pct_change().fillna(0)\n",
    "\n",
    "# --- Target Variable ---\n",
    "# Binary target: 1 if next day's Spot_Close is higher, else 0.\n",
    "data['target'] = (data['Spot_Close'].shift(-1) > data['Spot_Close']).astype(int)\n",
    "data = data.iloc[:-1]  # Drop last row due to shift\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "scaler = MinMaxScaler()\n",
    "data['Spot_Close_scaled'] = scaler.fit_transform(data[['Spot_Close']])\n",
    "data['daily_return_scaled'] = scaler.fit_transform(data[['daily_return']])\n",
    "\n",
    "print(\"\\nData after preprocessing and feature engineering:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\3592349862.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\3592349862.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 2: Basic Cleanup ---\n",
    "df = data.copy()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Clip outliers in GEX-related columns to reduce noise\n",
    "gex_columns = [col for col in df.columns if 'gex' in col.lower()]\n",
    "df[gex_columns] = df[gex_columns].clip(lower=df[gex_columns].quantile(0.01),\n",
    "                                       upper=df[gex_columns].quantile(0.99), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\2774169941.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['spot_rolling_mean'] = df['Spot_Close'].rolling(window=5).mean().fillna(method='bfill')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\2774169941.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['spot_rolling_std'] = df['Spot_Close'].rolling(window=5).std().fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 3: Feature Engineering ---\n",
    "\n",
    "# Add return features\n",
    "df['spot_return'] = df['Spot_Close'].pct_change().fillna(0)\n",
    "df['spot_rolling_mean'] = df['Spot_Close'].rolling(window=5).mean().fillna(method='bfill')\n",
    "df['spot_rolling_std'] = df['Spot_Close'].rolling(window=5).std().fillna(method='bfill')\n",
    "\n",
    "# Add target label: Buy (1), Sell (-1), Hold (0)\n",
    "threshold = 0.001  # 0.1% movement\n",
    "df['future_return'] = df['Spot_Close'].pct_change(periods=5).shift(-5)\n",
    "df['target'] = 0\n",
    "df.loc[df['future_return'] > threshold, 'target'] = 1\n",
    "df.loc[df['future_return'] < -threshold, 'target'] = -1\n",
    "df.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "# --- Step 4: Prepare features and labels ---\n",
    "feature_cols = [col for col in df.columns if col not in ['future_return', 'target']]\n",
    "X = df[feature_cols]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_28448\\2847396058.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(X.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fill any remaining NaNs (e.g., from rolling windows)\n",
    "X.fillna(X.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'timestamp' in X.columns:\n",
    "    X = X.drop(columns=['timestamp'])\n",
    "\n",
    "# Alternatively, drop any non-numeric columns\n",
    "X = X.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Cleanups Before Model ---\n",
    "# Remove any accidentally included datetime columns\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro Score (5-Fold CV): 0.46268858964464776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='f1_macro')\n",
    "print(\"F1 Macro Score (5-Fold CV):\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=skf)\n",
    "\n",
    "# Print the full classification report\n",
    "print(\"Classification Report (5-Fold CV):\")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"predicted_signal\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_test.index, df_test['Spot_Close'], label='Spot Close Price', color='gray')\n",
    "\n",
    "buy_signals = df_test[df_test['predicted_signal'] == 1]\n",
    "sell_signals = df_test[df_test['predicted_signal'] == -1]\n",
    "\n",
    "plt.scatter(buy_signals.index, buy_signals['Spot_Close'], label='Buy Signal', marker='^', color='green')\n",
    "plt.scatter(sell_signals.index, sell_signals['Spot_Close'], label='Sell Signal', marker='v', color='red')\n",
    "\n",
    "plt.title(\"Buy/Sell Signals on AAPL\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
